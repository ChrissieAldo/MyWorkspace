---
title: "EmployeeAttritionAnalysis"
author: "Chrissie Aldo"
date: '2022-06-12'
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages, eval=TRUE, echo=TRUE}
library(dplyr)
library(ggplot2)
library(gridExtra)
library(jtools)
library(smotefamily)
library(tidyverse)
library(psych)
library(e1071)
library(caret)
library(randomForest)
library(caTools)
library(party)
library(rpart)
library(rpart.plot)
library(pROC)

```


```{r readData, eval=TRUE, echo=TRUE }

data <- read.csv("~/dataset/group project/AttritionData.csv", header=T)
data

```

```{r visualize1, eval=TRUE, echo=TRUE}
pAttrition <- data %>% group_by(Attrition) %>% summarise(count = n()) %>% 
    mutate(Percent = (count / sum(count))*100) %>% 
    ggplot() + geom_bar(aes(y=Percent, x=Attrition, fill=Attrition), stat = "identity")
pDept <- data %>% ggplot(aes(Department, fill=Attrition)) + geom_bar()  + coord_flip()
pMarital <- data %>% ggplot(aes(MaritalStatus, fill=Attrition)) + geom_bar()
pGender <- data %>% ggplot(aes(Gender, fill=Attrition)) + geom_bar()
grid.arrange(pAttrition, pDept, pMarital,pGender, ncol=2, nrow=2)

data %>% ggplot(aes(JobRole, fill=Attrition)) + geom_bar() + coord_flip() + coord_flip() +  labs(title="Attrition by Job Role", y="Employees")
```


```{r readDataset, eval=TRUE, echo=TRUE}

#dataset with numerical values
data1<- read.csv("~/dataset/group project/numAttritionData.csv", header=T)
data1

```



```{r visualize2, eval=TRUE, echo=TRUE}
pIncome <- data1 %>% ggplot(aes(MonthlyIncome, Attrition)) + geom_smooth() 
pDistance <- data1 %>% ggplot(aes(DistanceFromHome, Attrition)) + geom_smooth()
pSalaryHike <- data1 %>% ggplot(aes(Percent3Hike, Attrition)) + geom_smooth()
pCompanies <- data1 %>% ggplot(aes(NumCompaniesWorked, Attrition)) + geom_smooth()


pAge <- data1 %>% ggplot(aes(Age, Attrition)) + geom_smooth()
pYearsCompany <- data1 %>% ggplot(aes(YearsAtCompany, Attrition)) + geom_smooth()

pPromotion <- data1 %>% ggplot(aes(YearsSinceLastPromotion, Attrition)) + geom_smooth()
pYearsManager <- data1 %>% ggplot(aes(YearsWithCurrManager, Attrition)) + geom_smooth()
pYearsWorking <- data1 %>% ggplot(aes(TotalWorkingYears, Attrition)) + geom_smooth()
grid.arrange(pIncome,pDistance,pSalaryHike,pCompanies,pAge,pYearsCompany,pPromotion,pYearsManager,pYearsWorking, ncol=3, nrow=3)

```

DATA PREPROCESSING (codes are added to the appendix)

```{r missingValues, eval=TRUE, echo=TRUE}

#to check if the dataset contains any missing values
missing_values <- sapply(data1, function(x) sum(is.na(x)))
sum(missing_values)

```


```{r removeNullValues, eval=TRUE, echo=TRUE}
df<- subset(data1, select = -Date_of_termination)
names(df)
```


```{r attritionValue, eval=TRUE, echo=TRUE}
table(df$Attrition) #the data is imbalance, No: 1233  Yes:237
str(df)
```


```{r oversampling, eval=TRUE, echo=TRUE}

new_df <- SMOTE(df[,-2],df[,2],K=7)
str(new_df)


```


```{r concatenate, eval=TRUE, echo=TRUE}
#concat attrition attribute 
table(new_df$data$Attrition)

df2<-new_df$syn_data
df2<-df2 |> mutate(Attrition=1,.after=Age)

df3<-bind_rows(df,df2)
df3

table(df3$Attrition) #No: 1233 Yes: 1185
#sample the dataset to get the training set and test set
#last few records have yes values

```


```{r eval=TRUE, echo=TRUE }
df3<-select(df3,-class)
df3
```


```{r vif, eval=TRUE, echo=TRUE}
#vif -> variance inflation factor

df4<-df3 %>% mutate(across(Age:Job_mode,as.integer)) #changing the attributes type to integer

df4$Attrition<-as.factor(df4$Attrition) #changing the attrition attribute type to factor

df4


m<-glm(Attrition~ .-JobLevel-MonthlyIncome-Year_of_Hire-Percent3Hike-JobRole-Age,data=df4,family=binomial)#logistic regression
summ(m,vifs=TRUE)
#remove attributes whose vif value is greater than 5 
#remove attributes whose pvalue is greater than 0.1



roc(df4$Attrition, m$fitted.values, plot=TRUE)

par(pty = "s")## pty sets the aspect ratio of the plot region. Two options:
##                "s" - creates a square plotting region
##                "m" - (the default) creates a maximal plotting region

roc(df4$Attrition, m$fitted.values, plot=TRUE)

roc(df4$Attrition, m$fitted.values, plot=TRUE, legacy.axes=TRUE)
roc(df4$Attrition, m$fitted.values, plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Postive Percentage", col="#377eb8", lwd=4)

## If we want to find out the optimal threshold we can store the 
## data used to make the ROC graph in a variable...
roc.info <- roc(df4$Attrition, m$fitted.values, legacy.axes=TRUE)
str(roc.info)

## and then extract just the information that we want from that variable.
roc.df <- data.frame(
  tpp=roc.info$sensitivities*100, ## tpp = true positive percentage
  fpp=(1 - roc.info$specificities)*100, ## fpp = false positive precentage
  thresholds=roc.info$thresholds)

head(roc.df)


## now let's look at the thresholds between TPP 60% and 80%...
roc.df[roc.df$tpp > 60 & roc.df$tpp < 80,]

## We can calculate the area under the curve...
roc(df4$Attrition, m$fitted.values, plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Postive Percentage", col="#377eb8", lwd=4, print.auc=TRUE)

## ...and the partial area under the curve.
roc(df4$Attrition, m$fitted.values, plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Postive Percentage", col="#377eb8", lwd=4, print.auc=TRUE, print.auc.x=45, partial.auc=c(100, 90), auc.polygon = TRUE, auc.polygon.col = "#377eb822")


```

```{r newDataset, eval=TRUE, echo=TRUE}
df4<-select(df4,-c("Age","JobLevel","MonthlyIncome","Year_of_Hire","Percent3Hike","JobRole"))
df4
#write.csv(df4,"numAttritionData_disc.csv")
#once the dataset is downloaded, remove the the first column(ie; the column before attrition attribute)
```


```{r eval=TRUE, echo=TRUE}
df5 <- df4
df6 <- df4
df7<-df4

```


NAIVE BAYES CLASSIFIER
```{r nbclassifier, eval=TRUE, echo=TRUE}
set.seed(1234)
#n <- sample(2, nrow(df5), replace = T, prob = c(0.8,0.2))
#train <- df5[n == 1,]
#test <- df5[n == 2,]

(emp_att<- length(df5$Attrition))
train_size <- round(emp_att * 0.7) #70% for training
test_size <- emp_att - train_size #rest for testing
emp_indx <-sample(seq(1:emp_att), train_size)
train_sample <- df5[emp_indx,]
test_sample <- df5[-emp_indx,]

classifier_NB <- naiveBayes(
  subset(train_sample, select = -Attrition),
  train_sample$Attrition, laplace = 1)
classifier_NB


predictions_NB <- predict(classifier_NB,
                          subset(test_sample, select = -Attrition))
table(predictions_NB, test_sample$Attrition)
round(sum(predictions_NB == test_sample$Attrition, na.rm = TRUE) / 
        length(test_sample$Attrition), digits = 2)

(confusionMatrix_NB <- confusionMatrix(table(predictions_NB, test_sample$Attrition)))




```

```{r}
df6
```


Random Forest Classifier

```{r rfclassifier, eval=TRUE, echo=TRUE}

df6$Attrition<- as.factor(df6$Attrition)
table(df6$Attrition)

set.seed(2236)

ind<- sample(2, nrow(df6), replace = TRUE, prob = c(0.7,0.3))
train<- df6[ind == 1,]
test<- df6[ind == 2,]


(classifier_RF <- randomForest(Attrition~., data=train, proximity = TRUE))
#OOB -: Out-Of-Bag error estimate. this means that (100-OOB) of the OOB samples were correctly classsified by the RF.

predictions_RF1 <- predict(classifier_RF, train)
(confusionMatrix_RF1 <- confusionMatrix(predictions_RF1, train$Attrition))

predictions_RF2 <- predict(classifier_RF, test)
(confusionMatrix_RF2 <- confusionMatrix(predictions_RF2, test$Attrition))

#fit1 <- rpart(Attrition~.,data = train_data, method = "class")
fit1 <- rpart(Attrition~.,data = test, method = "class")
#rpart.plot(fit1, extra=106)
rpart.plot(fit1, extra=106)


plot(classifier_RF)
varImpPlot(classifier_RF)
importance(classifier_RF)



#for all attributes
importanceOrder=order(-classifier_RF$importance)
names=rownames(classifier_RF$importance)[importanceOrder][1:15]
par(mfrow=c(5, 3), xpd=NA)
for (name in names)
  partialPlot(classifier_RF, df, eval(name), main=name, xlab=name,ylim=c(-.2,.9))


```


Decision Tree 

```{r dtclassifier, eval=TRUE, echo=TRUE}
set.seed(5432)
sample_data<- sample.split(df7, SplitRatio = 0.7)
train_data<- subset(df7, sample_data == TRUE)
test_data<- subset(df7, sample_data == FALSE)

dt_model <- ctree(Attrition~., train_data)
#plot(dt_model)

predict_model <- predict(dt_model, test_data)

e_at<- table(test_data$Attrition, predict_model)
e_at


ac_test<- sum(diag(e_at))/ sum(e_at)
ac_test

(confusionMatrix_DT <- confusionMatrix(predict_model, test_data$Attrition))

#fit1 <- rpart(Attrition~.,data = train_data, method = "class")
fit2 <- rpart(Attrition~.,data = test_data, method = "class")
#rpart.plot(fit1, extra=106)
rpart.plot(fit2, extra=106)

```


